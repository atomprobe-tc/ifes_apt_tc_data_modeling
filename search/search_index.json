{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Documentation for ifes_apt_tc_data_modeling","text":"<p>A Python software module for reading file formats that are used in the research field of atom probe tomography and field ion microscopy.</p> Project and community <p>Any questions or suggestions? Get in touch!</p> <p>The work is supported by the International Field Emission Society (IFES) Atom Probe Tomography Technical Committee (APT TC)</p> <p>The work is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 460197019 (FAIRmat).</p> <p>The library is used for the pynxtools-apm to standardized atom probe data using NeXus</p>"},{"location":"index.html#tutorial","title":"Tutorial","text":"<p>Installation guides exist for users and developers.</p> <ul> <li>Install for users</li> <li>Install for developers</li> <li>Compile the documentation</li> </ul>"},{"location":"index.html#how-to-guides","title":"How-to guides","text":""},{"location":"index.html#learn","title":"Learn","text":"<p>Background knowledge to specific topics.</p> <ul> <li>Exchange</li> <li>Provenance</li> <li>Specifications</li> <li>NeXus NXapm</li> </ul>"},{"location":"index.html#reference","title":"Reference","text":""},{"location":"explanation/learn.html","title":"Exchange","text":""},{"location":"explanation/learn.html#calling-for-more-exchange-about-metadata-in-the-field","title":"Calling for more exchange about (meta)data in the field","text":"<p>The proprietary software package IVAS now APSuite by AMETEK/Cameca is the workhorse for data acquisition and analysis in the atom probe community. Several file formats that this software uses are proprietary with the <code>.apt</code> file format as one exception. The idea of the <code>.apt</code> file format is opening up atom probe data from Cameca instrument, i.e., Local Electrode Atom Probe (LEAP) instruments for scientific data analysis and public dissemination. The International Field Emission Society (IFES) and Cameca have worked together to communicate a documentation for the format which enabled the community to develop open-source reading capabilities as implemented also in the <code>ifes_apt_tc_data_modeling</code> library through its <code>apt</code> module.</p> <p>While <code>.apt</code> is more and more getting accepted, traditional text and binary file formats are still commonly used in daily atom probe research practice. Not for all of these formats formal specifications exist. This makes working with these formats in software tools other than from AMETEK/Cameca trickier and error-prone.</p> <p>A practical solution to raise at least awareness of this problem has been that scientists collect examples (instances) of files in respective formats. Pieces of information about the content and formatting of atom probe file formats were reported in the literature (e.g. in the books by D. Larson et al. or B. Gault et al.. Atom probers like Daniel Haley have contributed substantially through raising awareness of the issue within the community. Consequently, individuals of the community invested into reverse engineering efforts about what these formats store and how this can be parsed using open-source software that is developed within the atom probe community and beyond.</p> <p>The <code>ifes_apt_tc_data_modeling</code> library bundles this knowledge highlighting though also that there are still gaps in our understanding. From an academic point of view these should be closed so that whenever possible atom probe data and metadata can be always communicated clearly with respect to what do certain numbers mean, i.e., what are the semantics and concepts behind the numbers and data items. </p> <p>As an example, the <code>.pos</code> file format stores a table of number quadruples which mostly are interpreted as reconstructed position and mass-to-charge-state ratio values. Often the latter column is hijacked though to report conceptually different quantities like identifier used to distinguish clusters of atoms. Which specific input data were used, which parameterization was used for the reconstruction algorithm whose results were stored in that <code>.pos</code> file. These questions pertaining to the workflow and provenance along the data lifecycle remain unaddressed. Other technical issues exist with file formats like <code>.pos</code> and <code>.epos</code>: These do not provide a magic number that identifies the file as a true <code>.pos</code> file such that software tools and humans could make substantiated assumptions.</p> <p>Needs for improvement exist also for ranging definitions file formats like the commonly used <code>.rrng</code>, <code>.rng</code>, and <code>.env</code> formats: These merely store the resulting ranging definitions but do not store details based on which peak finding algorithm or even which mass-to-charge-state-ratio value array they were defined with. A more detailed discussion of these limitations is provided in the literature.</p> <p>The <code>ifes_apt_tc_data_modeling</code> library was developed after observing that many researchers in atom probe uses custom written code for reading atom probe data via classical file formats. While for several formats this is a rather simple programming exercise, it led though to parallel developments and many implementations that target only specific use cases instead of a general enough implementations with functionalities for all possible elements, ion types, and edge cases.</p>"},{"location":"explanation/nxapm.html","title":"NeXus NXapm","text":""},{"location":"explanation/nxapm.html#towards-a-global-data-model-for-atom-probe-research","title":"Towards a global data model for atom probe research","text":"<p>Recently, coordinated efforts that have build on the collective knowledge of the atom probe community have resulted in the development of a covering data model for atom probe tomography and related field ion microscopy. This model uses the NeXus data modeling framework. The proposed data model <code>NXapm</code> captures all aspects of data acquisition and data analysis to arrive at calibrated reconstructed datasets with applied ranging definitions with transparent communication about peak fitting and analysis routines. The proposal has recently been proposed for standardization with the NeXus international Advisory Committee (NIAC). The proposal was successful resulting in <code>NXapm</code> since July 2025 being an official part of the NeXus standard. This is the respective pull request.</p> <p>The activities have been acknowledged by key members of the atom probe community thus qualifying as suggested to be used global reporting standard for atom probe.</p> <p>With pynxtools-apm a reference implementation exists that maps file formats in atom probe except for the CamecaROOT-based ones to <code>NXapm</code>.</p>"},{"location":"explanation/provenance.html","title":"Provenance","text":""},{"location":"explanation/provenance.html#provenance-and-how-to-improve-on-it","title":"Provenance and how to improve on it","text":"<p>Atom probers should be aware that file formats like <code>.pos</code>, <code>.epos</code>, or <code>.apt</code> are neither raw data nor follow a clear technical documentation that is completely available to the public. Therefore, all current file formats are not meeting the FAIR principles.</p> <p>Instead, share <code>.rraw</code>, <code>.str</code>, <code>.rhit</code>, and <code>.hits</code> files when working with AMETEK/Cameca instruments. Ideally, you add unique identifiers (such as SHA256 checksums) for each file. A documentation how you can do this was issued by your IFES APT TC colleagues (How to hash your data).</p>"},{"location":"explanation/suggestions.html","title":"Specifications","text":""},{"location":"explanation/suggestions.html#improve-on-building-and-communicating-file-format-specifications","title":"Improve on building and communicating file format specifications","text":"<p>File formats, data models, in (almost every) research field may not be fully documented. A checklist of the necessary pieces of information and documentation required to call a data model, data schema, and/or file format fully documented in accordance with the FAIR data and research software stewardship principles is given below:</p> <ol> <li>Each piece of information (bit/byte) is documented.</li> <li>This documentation fulfills the FAIR principles, i.e.    Wilkinson et al., 2016 and    Barker et al., 2022    For binary files, tools like kaitai struct offer a    solution to describe the exact binary information content in a data    item. This can be a file but also the storage of a database entry or the    response of a call to an API.    Let alone the binary structure is insufficient tough.</li> <li>To each piece of information there has to exist also a parameterized description,    what this piece of information conceptually means. One way to arrive at such    description is to use a data schema or ontology.    It is important to mention that the concepts in this schema/ontology have    unique identifier so that each data item/piece of information is identifiable    as an instance of an entry in a database or a knowledge graph.    This holds independently of which research data management system    or electronic lab notebook is used.</li> <li>In addition, it is very useful if timestamps are associated with each data item    (ISO8061 including time zone information) so that it is possible to create a    timeline of the context in which and when the e.g. file was created.</li> </ol> <p>The first and second point is known as a specification, while the third and fourth point emphasize that the contextualization and provenance is key to make a specification complete and useful.</p>"},{"location":"tutorial/compile_docs.html","title":"Compile the documentation","text":"<p>Provided <code>ifes_apt_tc_data_modeling</code> library was installed with the optional dependency <code>docs</code> the documentation can be compiled locally using the mkdocs:</p> <pre><code>mkdocs build\nmkdocs serve\n</code></pre>"},{"location":"tutorial/install_devs.html","title":"Installation as a developer","text":"<p>Developers should clone the repository and install in a Python virtual or conda environment:</p> <pre><code>git clone https://www.github.com/atomprobe-tc/ifes_apt_tc_data_modeling.git\ncd ifes_apt_tc_data_modeling\npython -m pip install --upgrade pip\npython -m pip install -e \".[dev,docs,ipynb]\"\n</code></pre> <p>This will install modules for linting, code styling, and unit testing via the pytest framework. Unit tests can then be started from the root directory of the installation with the following call:</p> <pre><code>pytest -sv tests\n</code></pre>"},{"location":"tutorial/install_user.html","title":"Installation as a user","text":"<p>To use this library create either a Python virtual environment or conda environment.</p> <p>The library can be used on Windows, Mac, or Unix, provided a Python version is installed. Exemplified for using a Python virtual environment and Python 3.12, firstly you should create a virtual environment \u2014 if you do not have one yet \u2014 in a directory on your local computer or server.</p> <pre><code>python3 -m venv .py3.12\nsource .py3.12/bin/activate\n</code></pre> <p>If you already have such environment or just created one, proceed with installing the library:</p> <pre><code>pip install ifes_apt_tc_data_modeling[ipynb]\n</code></pre> <p>This will install the module and jupyterlab whereby the notebook with examples become executable. The jupyterlab server is started with.</p> <pre><code>jupyter-lab\n</code></pre> <p>The notebook to run is the following <code>examples/ExamplesForUsersOrDevelopers.ipynb</code></p>"}]}